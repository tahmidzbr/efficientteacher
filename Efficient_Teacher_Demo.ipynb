{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zgurb-KQGp8pHfjNPEuincrjZPZAOHgd",
      "authorship_tag": "ABX9TyP7dSBLtkulIDZPViEI6f33",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahmidzbr/efficientteacher/blob/main/Efficient_Teacher_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup Environment to load and install Efficient Teacher"
      ],
      "metadata": {
        "id": "TK56vYafD37D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive to copy pretrained weights to notebook"
      ],
      "metadata": {
        "id": "sLRIR1NMDNRx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0nV_nzGo166",
        "outputId": "818f4f74-6f12-46b6-ea60-99ef31401355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone the forked repository for Efficient Teacher"
      ],
      "metadata": {
        "id": "CGj4lC6KDVvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/tahmidzbr/efficientteacher.git\n",
        "%cd efficientteacher\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMCeg1l1rPvf",
        "outputId": "9dfbf220-ddb4-4551-d92d-b2a6c4c626a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'efficientteacher'...\n",
            "remote: Enumerating objects: 435, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 435 (delta 55), reused 75 (delta 49), pack-reused 337\u001b[K\n",
            "Receiving objects: 100% (435/435), 3.60 MiB | 28.16 MiB/s, done.\n",
            "Resolving deltas: 100% (198/198), done.\n",
            "/content/efficientteacher\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install all dependencies"
      ],
      "metadata": {
        "id": "8Dl7w1mpDaun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt  # Replace with actual file if different\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQmyV5HUrUXW",
        "outputId": "db2d1438-31eb-4296-e24a-ca5609216dba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.15.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.13.1)\n",
            "Collecting onnx-simplifier>=0.3.6 (from -r requirements.txt (line 27))\n",
            "  Downloading onnx_simplifier-0.4.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting thop (from -r requirements.txt (line 37))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 11)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 11)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 11)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 11)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 11)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 11)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->-r requirements.txt (line 11)) (2.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.5.2)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.0.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.3.post1)\n",
            "Collecting onnx (from onnx-simplifier>=0.3.6->-r requirements.txt (line 27))\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier>=0.3.6->-r requirements.txt (line 27)) (13.7.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 27)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 27)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier>=0.3.6->-r requirements.txt (line 27)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.2.2)\n",
            "Installing collected packages: onnx, thop, onnx-simplifier\n",
            "Successfully installed onnx-1.15.0 onnx-simplifier-0.4.35 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dataset Preparation\n",
        "\n",
        "### Download COCO images and labels and process into the default format for YOLOv5."
      ],
      "metadata": {
        "id": "ByZvhzRmDlrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash data/get_coco.sh"
      ],
      "metadata": {
        "id": "NixfJec5EKlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e2b01a-ac39-4ec7-ed48-b4fb2084d62e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels.zip  ...\n",
            "Downloading http://images.cocodataset.org/zips/train2017.zip ...\n",
            "Downloading http://images.cocodataset.org/zips/val2017.zip ...\n",
            "############################################################################################# 100.0%\n",
            "############################################################################################# 100.0%\n",
            "############################################################################################# 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Organize the data directories to match the structure as given in the README of the repo (just run the cells below, and it should take care of it for you)."
      ],
      "metadata": {
        "id": "UwwAHWZUEOnK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```efficientteacher\n",
        "  ├── data\n",
        "  └── datasets\n",
        "      └── coco  ← downloads here (20.1 GB)\n",
        "           └── images\n",
        "           └── labels\n",
        "```"
      ],
      "metadata": {
        "id": "KSLYnXhoEaby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy dataset to ensure correct directory structure\n",
        "!cp -r ../datasets ./"
      ],
      "metadata": {
        "id": "Jm8H-OHHrdYM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the train/val dataset lists"
      ],
      "metadata": {
        "id": "TwzAJCWKEoUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash data/get_label.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMrdR0A_vXS1",
        "outputId": "2c3d92e3-417d-480d-f24e-b77b51a974ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/BowieHsu/EfficientTeacher/archive/refs/tags/data_list.zip  ...\n",
            "-#O#- #    #                                                                                       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace the \"local_path\" with your dataset path of the Efficient Teacher project folder"
      ],
      "metadata": {
        "id": "6Jq1cTPKE2TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# need to adjust the local_path for the .txt files\n",
        "%cd datasets/EfficientTeacher-data_list/\n",
        "!sed -i 's|local_path|/content/efficientteacher|' *.txt\n",
        "\n",
        "# return to the project folder\n",
        "%cd /content/efficientteacher\n"
      ],
      "metadata": {
        "id": "Yv57jfWoqJbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45784fe1-96db-4b21-8cc7-c04291c17c3b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/efficientteacher/datasets/EfficientTeacher-data_list\n",
            "/content/efficientteacher\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Evaluation/Inference\n",
        "\n",
        "### To run evaluation using the pre-trained models, run the commands:"
      ],
      "metadata": {
        "id": "XVCZz5-1j7VT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!python val.py --data /content/efficientteacher/configs/ssod/coco-standard/yolov5l_coco_ssod_10_percent.yaml --weights /content/drive/MyDrive/pretrained_weights/efficient-yolov5s.pt --batch-size 32 --imgsz 640\n",
        "#!python val.py --data /content/efficientteacher/configs/ssod/coco-standard/yolov5l_coco_ssod_10_percent.yaml --weights /content/drive/MyDrive/pretrained_weights/efficient-yolov5s-ssod.pt --batch-size 32 --imgsz 640\n",
        "#!python val.py --data /content/efficientteacher/configs/ssod/coco-standard/yolov5l_coco_ssod_10_percent.yaml --weights /content/drive/MyDrive/pretrained_weights/efficient-yolov5m.pt --batch-size 32 --imgsz 640\n",
        "#!python val.py --data /content/efficientteacher/configs/ssod/coco-standard/yolov5l_coco_ssod_10_percent.yaml --weights /content/drive/MyDrive/pretrained_weights/efficient-yolov5m-ssod.pt --batch-size 32 --imgsz 640\n",
        "!python val.py --data /content/efficientteacher/configs/ssod/coco-standard/yolov5l_coco_ssod_10_percent.yaml --weights /content/drive/MyDrive/pretrained_weights/efficient-yolov5l.pt --batch-size 32 --imgsz 640\n",
        "#!python val.py --data /content/efficientteacher/configs/ssod/coco-standard/yolov5l_coco_ssod_10_percent.yaml --weights /content/drive/MyDrive/pretrained_weights/efficient-yolov5l-ssod.pt --batch-size 32 --imgsz 640\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7UkQixv5die",
        "outputId": "697ace18-a474-4f44-9e8c-6050dd925dec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/efficientteacher/configs/ssod/coco-standard/yolov5l_coco_ssod_10_percent.yaml, weights=['/content/drive/MyDrive/pretrained_weights/efficient-yolov5l.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, val_ssod=False, num_points=0, cfg=, val_dp1000=False\n",
            "EfficientTeacher  d347793 torch 2.1.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n",
            "\n",
            "parse model_type:  /content/drive/MyDrive/pretrained_weights/efficient-yolov5l.pt\n",
            "Fusing layers... \n",
            "Model summary: 365 layers, 46533693 parameters, 457725 gradients\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Flops 109.15G Params 46.53M\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/EfficientTeacher-data_list/val2017.cache' images and labels... 4952 found, 48 missing, 0 empty, 0 corrupted: 100% 5000/5000 [00:00<?, ?it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  59% 93/157 [01:33<01:04,  1.00s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/efficientteacher/val.py\", line 528, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/efficientteacher/val.py\", line 523, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/efficientteacher/val.py\", line 301, in run\n",
            "    outputs = model(img, augment=augment)  # inference and training outputs\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/efficientteacher/utils/detect_multi_backend.py\", line 240, in forward\n",
            "    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/efficientteacher/models/detector/yolo.py\", line 86, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "  File \"/content/efficientteacher/models/detector/yolo.py\", line 91, in _forward_once\n",
            "    x = self.head(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/efficientteacher/models/head/yolov5_head.py\", line 74, in forward\n",
            "    y[..., class_range] = x[i][..., class_range].sigmoid()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Training\n",
        "\n",
        "### The following code runs training on already configured model yaml files and dataset config files."
      ],
      "metadata": {
        "id": "FfeurBkDkkGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --cfg configs/ssod/coco-standard/yolov5l_coco_ssod_10_percent.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-YUaj-_kjos",
        "outputId": "3023e2cf-adb2-47ac-9880-c87d082d017f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-18 03:18:07.795372: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-18 03:18:07.795488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-18 03:18:07.918962: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-18 03:18:10.413707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m__immutable__=False, __deprecated_keys__=set(), __renamed_keys__={}, __new_allowed__=False\n",
            "EfficientTeacher  d347793 torch 2.1.0+cu121 CUDA:0 (Tesla T4, 15102.0625MB)\n",
            "\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize EfficientTeacher runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir exp_ssod', view at http://localhost:6006/\n",
            "Model summary: 478 layers, 47943549 parameters, 47943549 gradients\n",
            "\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 110 weight, 101 weight (no decay), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'datasets/EfficientTeacher-data_list/train2017_p10.0_labeled_data' images and labels...3328 found, 34 missing, 0 empty, 0 corrupted:  28% 3362/11828 [00:07<00:18, 445.85it/s]Process ForkPoolWorker-2:\n",
            "Process ForkPoolWorker-1:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/efficientteacher/utils/datasets.py\", line 716, in __init__\n",
            "    cache, exists = np.load(cache_path, allow_pickle=True).item(), True  # load dict\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 405, in load\n",
            "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'datasets/EfficientTeacher-data_list/train2017_p10.0_labeled_data.cache'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 856, in next\n",
            "    item = self._items.popleft()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1182, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 861, in next\n",
            "    self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/efficientteacher/train.py\", line 84, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/efficientteacher/train.py\", line 72, in main\n",
            "    trainer = SSODTrainer(cfg, device, callbacks, LOCAL_RANK, RANK, WORLD_SIZE)\n",
            "  File \"/content/efficientteacher/trainer/ssod_trainer.py\", line 60, in __init__\n",
            "    self.build_dataloader(cfg, callbacks)\n",
            "  File \"/content/efficientteacher/trainer/ssod_trainer.py\", line 223, in build_dataloader\n",
            "    self.train_loader, self.dataset = create_dataloader(self.data_dict['train'], self.imgsz, self.batch_size // self.WORLD_SIZE, gs, self.single_cls,\n",
            "  File \"/content/efficientteacher/utils/datasets.py\", line 324, in create_dataloader\n",
            "    dataset = LoadImagesAndLabels(path, imgsz, batch_size,\n",
            "  File \"/content/efficientteacher/utils/datasets.py\", line 721, in __init__\n",
            "    cache, exists = self.cache_labels(cache_path, prefix), False  # cache\n",
            "  File \"/content/efficientteacher/utils/datasets.py\", line 858, in cache_labels\n",
            "    for im_file, l, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1197, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1303, in close\n",
            "    self.display(pos=0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1496, in display\n",
            "    self.sp(self.__str__() if msg is None else msg)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 462, in print_status\n",
            "    fp_write('\\r' + s + (' ' * max(last_len[0] - len_s, 0)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 455, in fp_write\n",
            "    fp.write(str(s))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/utils.py\", line 195, in inner\n",
            "    return func(*args, **kwargs)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 - Training SSOD on customized dataset\n",
        "\n",
        "### To-do"
      ],
      "metadata": {
        "id": "tvX66m4nk8jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"tahmidzbr\"\n",
        "!git config --global user.email \"tahmidzbr@gmail.com\"\n"
      ],
      "metadata": {
        "id": "FZwHUsI7lzZn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr9rk6YOl46V",
        "outputId": "786c2166-0b9d-4a5f-89c4-83b2050412d4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t detect.py  models\t README.zh-CN.md   setup.py\t\t  utils\n",
            "configs  export.py  NOTICE\t requirements.txt  SSL_detection_2.ipynb  val.py\n",
            "data\t exp_ssod   __pycache__  runs\t\t   trainer\n",
            "deploy\t LICENSE    README.md\t scripts\t   train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r pretrained_weights"
      ],
      "metadata": {
        "id": "YfvPLqXwl7Ub"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r datasets"
      ],
      "metadata": {
        "id": "1uJUg6_3mAkL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add ."
      ],
      "metadata": {
        "id": "KC2H1eD4mCtr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4YqeHlUmNfb",
        "outputId": "2d4d04dd-259a-4a60-92ef-18b1f7306297"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git restore --staged <file>...\" to unstage)\n",
            "\t\u001b[32mnew file:   exp_ssod/exp11/events.out.tfevents.1705547892.6ef2ad448241.31777.0\u001b[m\n",
            "\t\u001b[32mnew file:   exp_ssod/exp11/opt.yaml\u001b[m\n",
            "\t\u001b[32mmodified:   val.py\u001b[m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"modified val.py and added easy constructors; created new colab notebook\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlHFdVpZmOfL",
        "outputId": "2f338df1-02fe-4634-ebc6-97e4cf963ae8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main f45f6c4] modified val.py and added easy constructors; created new colab notebook\n",
            " 3 files changed, 427 insertions(+), 2 deletions(-)\n",
            " create mode 100644 exp_ssod/exp11/events.out.tfevents.1705547892.6ef2ad448241.31777.0\n",
            " create mode 100644 exp_ssod/exp11/opt.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fzK8KjgmUXb",
        "outputId": "60837cb7-b7e0-417b-ead8-5ac5252ae799"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "username = getpass('GitHub Username: ')\n",
        "password = getpass('GitHub Password: ')\n",
        "os.environ['GITHUB_AUTH'] = f\"{username}:{password}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlSr8X_EmmoM",
        "outputId": "bf38a9e8-d456-4789-944c-bb8118eeccc9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GitHub Username: ··········\n",
            "GitHub Password: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXXdS3KBm7GM",
        "outputId": "604b65d8-157f-4009-820b-a2a470dbdee1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ['GITHUB_AUTH'] = getpass('Enter your GitHub token: ')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5tkur7QnC1b",
        "outputId": "67246dc4-38b5-4d45-fcd6-7e2c683732ae"
      },
      "execution_count": 38,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GitHub token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push https://tahmidzbr:${GITHUB_AUTH}@github.com/tahmidzbr/efficientteacher.git\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY3ldETYntcc",
        "outputId": "0a3e64c2-b12a-488e-fcd9-fa5c44d0d410"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enumerating objects: 10, done.\n",
            "Counting objects:  10% (1/10)\rCounting objects:  20% (2/10)\rCounting objects:  30% (3/10)\rCounting objects:  40% (4/10)\rCounting objects:  50% (5/10)\rCounting objects:  60% (6/10)\rCounting objects:  70% (7/10)\rCounting objects:  80% (8/10)\rCounting objects:  90% (9/10)\rCounting objects: 100% (10/10)\rCounting objects: 100% (10/10), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  14% (1/7)\rCompressing objects:  28% (2/7)\rCompressing objects:  42% (3/7)\rCompressing objects:  57% (4/7)\rCompressing objects:  71% (5/7)\rCompressing objects:  85% (6/7)\rCompressing objects: 100% (7/7)\rCompressing objects: 100% (7/7), done.\n",
            "Writing objects:  14% (1/7)\rWriting objects:  28% (2/7)\rWriting objects:  42% (3/7)\rWriting objects:  57% (4/7)\rWriting objects:  71% (5/7)\rWriting objects:  85% (6/7)\rWriting objects: 100% (7/7)\rWriting objects: 100% (7/7), 3.13 KiB | 3.13 MiB/s, done.\n",
            "Total 7 (delta 3), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/tahmidzbr/efficientteacher.git\n",
            "   d347793..f45f6c4  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mR0gL3ZRoEOM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}